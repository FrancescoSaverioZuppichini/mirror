{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mirror\n",
    "## Pytorch CNN Visualisation Tool\n",
    "\n",
    "This is a raw beta so expect lots of things to change and improve over time.\n",
    "\n",
    "![alt](https://github.com/FrancescoSaverioZuppichini/mirror/blob/master/resources/mirror.gif?raw=true)\n",
    "\n",
    "### Getting started\n",
    "\n",
    "To install mirror run\n",
    "\n",
    "```\n",
    "pip install git+https://github.com/FrancescoSaverioZuppichini/mirror.git\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "A basic example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"mirror.App\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [18/Jul/2019 15:48:10] \"GET /static/css/main.fd8c6979.chunk.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Jul/2019 15:48:10] \"GET /api/inputs HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Jul/2019 15:48:10] \"GET /api/model HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Jul/2019 15:48:10] \"GET /api/visualisation HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Jul/2019 15:48:10] \"GET /api/model/image/5875341241359/5875341241359/1647183868692822170/%3Cbuilt-in%20function%20id%3E/0 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [18/Jul/2019 15:48:10] \"GET /api/model/image/5875341241359/5875341241359/1647205858925377690/%3Cbuilt-in%20function%20id%3E/1 HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from mirror import mirror\n",
    "from mirror.visualisations import *\n",
    "from PIL import Image\n",
    "from torchvision.models import resnet101, resnet18, vgg16, alexnet\n",
    "from torchvision.transforms import ToTensor, Resize, Compose\n",
    "\n",
    "# create a model\n",
    "model = vgg16(pretrained=True)\n",
    "# open some images\n",
    "cat = Image.open(\"./cat.jpg\")\n",
    "dog_and_cat = Image.open(\"./dog_and_cat.jpg\")\n",
    "# resize the image and make it a tensor\n",
    "to_input = Compose([Resize((224, 224)), ToTensor()])\n",
    "# call mirror with the inputs and the model\n",
    "mirror([to_input(cat), to_input(dog_and_cat)], model, visualisations=[WebBackProp, WebGradCam, WebDeepDream])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will automatic open a new tab in your browser\n",
    "\n",
    "![alt](https://github.com/FrancescoSaverioZuppichini/mirror/blob/master/resources/mirror.png?raw=true)\n",
    "\n",
    "On the left you can see your model tree structure, by clicking on one layer all his children are showed. On the right there are the visualisation settings. You can select your input by clicking on the bottom tab.\n",
    "\n",
    "![alt](https://raw.githubusercontent.com/FrancescoSaverioZuppichini/mirror/master/resources/inputs.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available Visualisations\n",
    "### Weights\n",
    "![alt](https://github.com/FrancescoSaverioZuppichini/mirror/blob/master/resources/weights.png?raw=true)\n",
    "### Deep Dream\n",
    "![alt](https://github.com/FrancescoSaverioZuppichini/mirror/blob/master/resources/deepdream.png?raw=true)\n",
    "### Back Prop / Guide Back Prop\n",
    "By clicking on the radio button 'guide', all the relus negative output will be set to zero producing a nicer looking image\n",
    "![alt](https://github.com/FrancescoSaverioZuppichini/mirror/blob/master/resources/backprop.png?raw=true)\n",
    "## Grad Cam / Guide Grad Cam\n",
    "![alt](https://github.com/FrancescoSaverioZuppichini/mirror/blob/master/resources/grad_cam.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Visualisation\n",
    "To create a visualisation you first have to subclass the `Visualisation` class by just define the `__call__` method to return an image and additional informations. The following example creates a custom visualisation that just repeat the input. We first define a custom Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mirror.visualisations import Visualisation\n",
    "\n",
    "class RepeatInput(Visualisation):\n",
    "\n",
    "    def __call__(self, inputs, layer, repeat=1):\n",
    "        return inputs.repeat(repeat, 1, 1, 1), None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class just repeat the input for `repeat` times. Now we have to create a `WebInterface` to make this class communicate with the application. Be careful to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mirror.visualisations import WebInterface\n",
    "\n",
    "class WebRepeatInput(WebInterface):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.visualisation = RepeatInput(self.module, self.device) # create your visualisation\n",
    "        self.repeat = 1 # define your parameters\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return 'Repeat'\n",
    "\n",
    "    @property\n",
    "    def params(self):\n",
    "        # maps the parameters to the UI\n",
    "        return {'repeat' : {\n",
    "                     'type' : 'slider',\n",
    "                     'min' : 1,\n",
    "                     'max' : 100,\n",
    "                     'value' : self.repeat,\n",
    "                     'step': 1,\n",
    "                     'params': {}\n",
    "                 }\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `__init__` method we instantiate our custom visualisation by passing `self.module` and `self.device`. Then, **we decleare each argument to the visualisation as a field of this class**. So, since `RepeatInput` takes as argument `repeat` we create a field `repeat` in `WebRepeatInput`. Then, we defined the name by overriding the property `name`. Finally, we override the property `params` to create the corresponding UI. `params` must return a dictionary where **each key are the names of the visualisations arguments**, in our case `repeat`, and the value is a dictionary where there is a key `value` mapped to the class field. This will allows `mirror` to dynamically update your fields based on the UI. In this example, we create a slider and it looks like\n",
    "\n",
    "![alt](https://github.com/FrancescoSaverioZuppichini/mirror/blob/master/resources/repeat_slider.jpg?raw=true)\n",
    "The final result is \n",
    "\n",
    "![alt](https://github.com/FrancescoSaverioZuppichini/mirror/blob/master/resources/repeat_example.jpg?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt](https://github.com/FrancescoSaverioZuppichini/mirror/blob/master/resources/dummy.jpg?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change the front-end\n",
    "All the front-end is developed usin [React](https://reactjs.org/) and [Material-UI](https://material-ui.com/), two very known frameworks, making easier for anybody to contribuite.\n",
    "\n",
    "You can customise the front-end by changing the source code in `mirror/client`. After that, you need to build the react app and move the file to the server static folder.\n",
    "\n",
    "**I was not able to serve the static file directly from the /mirror/client/build folder** if you know how to do it any pull request is welcome :)\n",
    "\n",
    "```\n",
    "cd ./mirror/mirror/client // assuming the root folder is called mirror\n",
    "npm run build\n",
    "```\n",
    "Then you need to move the fiels from the `mirror/mirror/client/build` folder to `mirror/mirror`. You can remove all the files in `mirror/mirro/static`\n",
    "```\n",
    "mv ./build/static ../ && cp ./build/* ../static/\n",
    "```\n",
    "\n",
    "### TODO\n",
    "- [x] Cache reused layer \n",
    "- [x] Make a generic abstraction of a visualisation in order to add more features  \n",
    "- [x] Add dropdown as parameter\n",
    "- [x] Add text field\n",
    "- [x] Support multiple inputs\n",
    "- [x] Support multiple models\n",
    "- Add all visualisation present here https://github.com/utkuozbulak/pytorch-cnn-visualizations\n",
    "    * [x] [Gradient visualization with vanilla backpropagation](#gradient-visualization)\n",
    "    * [x] [Gradient visualization with guided backpropagation](#gradient-visualization) [1]\n",
    "    * [x] [Gradient visualization with saliency maps](#gradient-visualization) [4]\n",
    "    * [x] [CNN filter visualization](#convolutional-neural-network-filter-visualization) [9]\n",
    "    * [x] [Deep dream](#deep-dream) [10]\n",
    "    * [ ] [Class specific image generation](#class-specific-image-generation) [4]\n",
    "    * [x] [Grad Cam](https://arxiv.org/abs/1610.02391)\n",
    "\n",
    "- [ ] Add a `output_transformation` params for each visualisation to allow better customisation \n",
    "- [ ] Add a `input_transformation` params for each visualisation to allow better customisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
